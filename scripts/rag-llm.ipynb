{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pdfminer.high_level import extract_text\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! Yes, I am here. How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
    "parser = StrOutputParser()\n",
    "chain = model | parser\n",
    "chain.invoke(\"hi, are you there gpt?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug and Play Context üö©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF to Txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf_path, output_txt_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '../files/Computer Age Statistical Inference Book.pdf'\n",
    "output_txt_path = '../files/Computer Age Statistical Inference Book.txt'  \n",
    "# pdf_to_text(pdf_path, output_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking Context for LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"../files/Computer Age Statistical Inference Book.txt\")\n",
    "text_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='The Work, Computer Age Statistical Inference, was Ô¨Årst published by Cambridge University Press.\\nc(cid:13) in the Work, Bradley Efron and Trevor Hastie, 2016.\\nCambridge University Press‚Äôs catalogue entry for the Work can be found at http: // www. cambridge. org/\\n9781107149892\\nNB: The copy of the Work, as displayed on this website, can be purchased through Cambridge University\\nPress and other standard distribution channels. This copy is made available for personal use only and must\\nnot be adapted, sold or re-distributed.\\nCorrected November 10, 2017.', metadata={'source': '../files/Computer Age Statistical Inference Book.txt'}), Document(page_content='The twenty-first century has seen a breathtaking expansion of statistical methodology, both in scope and in influence. ‚ÄúBig data,‚Äù ‚Äúdata science,‚Äù and ‚Äúmachine learning‚Äù have become familiar terms in the news, as statistical methods are brought to bear upon the enormous data sets of modern science and commerce. How did we get here? And where are we going?This book takes us on an exhilarating journey through the revolution in data analysis following the introduction of electronic computation in the 1950s. Beginning with classical inferential theories ‚Äì Bayesian, frequentist, Fisherian ‚Äì individual chapters take up a series of influential topics: survival analysis, logistic regression, empirical Bayes, the jackknife and bootstrap, random forests, neural networks, Markov chain Monte Carlo, inference after model selection, and dozens more. The distinctly modern approach integrates methodology and algorithms with statistical inference. The book ends with speculation on the future direction', metadata={'source': '../files/Computer Age Statistical Inference Book.txt'})]\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(text_documents)\n",
    "print(documents[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = DocArrayInMemorySearch.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='What might be called the strong deÔ¨Ånition of frequentism insists on exact\\nfrequentist correctness under experimental repetitions. Pivotality, unfortu-\\nnately, is unavailable in most statistical situations. Our looser deÔ¨Ånition\\nof frequentism, supplemented by devices such as those above,7 presents a\\nmore realistic picture of actual frequentist practice.\\n\\n2.2 Frequentist Optimality\\n\\nThe popularity of frequentist methods reÔ¨Çects their relatively modest math-\\nematical modeling assumptions: only a probability model F (more exactly\\na family of probabilities, Chapter 3) and an algorithm of choice t.x/. This\\nÔ¨Çexibility is also a defect in that the principle of frequentist correctness\\ndoesn‚Äôt help with the choice of algorithm. Should we use the sample mean\\nto estimate the location of the gfr distribution? Maybe the 25% Win-\\nsorized mean would be better, as Table 2.1 suggests.', metadata={'source': '../files/Computer Age Statistical Inference Book.txt'}),\n",
       " Document(page_content='Frequentism cannot claim to be a seamless philosophy of statistical in-\\nference. Paradoxes and contradictions abound within its borders, as will\\nbe shown in the next chapter. That being said, frequentist methods have\\na natural appeal to working scientists, an impressive history of success-\\nful application, and, as our list of Ô¨Åve ‚Äúdevices‚Äù suggests, the capacity to\\nencourage clever methodology. The story that follows is not one of aban-\\ndonment of frequentist thinking, but rather a broadening of connections\\nwith other methods.\\n\\n2.3 Notes and Details', metadata={'source': '../files/Computer Age Statistical Inference Book.txt'}),\n",
       " Document(page_content='Despite its simplicity, or perhaps because of it, objective Bayes procedures\\nare vulnerable to criticism from both ends of the statistical spectrum. From\\nthe subjectivist point of view, objective Bayes is only partially Bayesian: it\\nemploys Bayes‚Äô theorem but without doing the hard work of determining a\\nconvincing prior distribution. This introduces frequentist elements into its\\npractice‚Äîclearly so in the case of Jeffreys‚Äô prior‚Äîalong with frequentist\\nincoherencies.\\n\\nFor the frequentist, objective Bayes analysis can seem dangerously un-\\ntethered from the usual standards of accuracy, having only tenuous large-\\nsample claims to legitimacy. This is more than a theoretical objection. The\\npractical advantages claimed for Bayesian methods depend crucially on the\\nÔ¨Åne structure of the prior. Can we safely ignore stopping rules or selective\\ninference (e.g., choosing the largest of many estimated parameters for spe-\\ncial attention) for a prior not based on some form of genuine experience?', metadata={'source': '../files/Computer Age Statistical Inference Book.txt'}),\n",
       " Document(page_content='Frequentist statistics has the advantage of being applicable to any algo-\\nrithmic procedure, for instance to our Cp/OLS estimator. This has great\\nappeal in an era of enormous data sets and fast computation. The draw-\\nback, compared with Bayesian statistics, is that we have no guarantee that\\nour chosen algorithm is best in any way. Classical statistics developed a\\ntheory of best for a catalog of comparatively simple estimation and testing\\nproblems. In this sense, modern inferential theory has not yet caught up\\nwith modern problems such as data-based model selection, though tech-\\nniques such as model averaging (e.g., bagging) suggest promising steps\\nforward.\\n\\n20.3 Selection Bias', metadata={'source': '../files/Computer Age Statistical Inference Book.txt'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "retriever.invoke(\"Who or what do frequentists criticize?\") # the pdf to text is garbage ... but great use case! ü§£"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup & Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "Answer the question based on the context below. Prior to finalizing your response, \n",
    "remember to clean the data and make sense of it. You are a pretrained LLM that understands\n",
    "common language, so use your best judgement if the text is too messy to give a definitive answer. \n",
    "If you can't answer the question because the text is too messy,\n",
    "reply \"The text is too messy to answer this question\". If you can't answer the question in general, reply \"I don't know\". \n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = RunnableParallel(context=retriever, question=RunnablePassthrough())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frequentists criticize objective Bayes procedures and their vulnerability to criticism from both subjectivist and frequentist perspectives.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = setup | prompt | model | parser\n",
    "chain.invoke(\"Who or what do frequentists criticize?\") # looks like neither of them were right...transformers for the win!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
